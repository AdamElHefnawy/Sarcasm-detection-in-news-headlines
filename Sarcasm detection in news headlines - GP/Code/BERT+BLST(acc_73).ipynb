{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1DsVSY4IhCw",
        "outputId": "2c08db0c-e5a9-420a-8adf-617d80107c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from transformers import BertTokenizer, TFBertModel\n"
      ],
      "metadata": {
        "id": "vTXbBACtItml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_json('Sarcasm_Headlines_Dataset.json', lines=True)"
      ],
      "metadata": {
        "id": "RDMs9ULBIwTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "0jxYdpxdJBsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocessing function to the 'headline' column\n",
        "data['headline'] = data['headline'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "iXd2sKIpJEBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['headline'], data['is_sarcastic'], test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "G7Ay1aI2JHNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text using BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "X_train_seq = tokenizer.batch_encode_plus(\n",
        "    X_train.tolist(),\n",
        "    truncation=True,\n",
        "    max_length=100,\n",
        "    padding='max_length',\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "X_test_seq = tokenizer.batch_encode_plus(\n",
        "    X_test.tolist(),\n",
        "    truncation=True,\n",
        "    max_length=100,\n",
        "    padding='max_length',\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "id": "Z8fTiNZBJJuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokenized sequences to numpy arrays\n",
        "X_train_pad = np.array(X_train_seq['input_ids'])\n",
        "X_test_pad = np.array(X_test_seq['input_ids'])\n"
      ],
      "metadata": {
        "id": "FXPSEsnpJMlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer), 100, input_length=100, trainable=False))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xlNXAla0JRw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping criteria\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "QyDxatlpJU5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_pad, y_train, epochs=35, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXCY5r7JJYnS",
        "outputId": "f2146b21-3db7-4920-c07e-3f6f24f5e0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "468/468 [==============================] - 23s 28ms/step - loss: 0.6208 - accuracy: 0.6423 - val_loss: 0.5722 - val_accuracy: 0.6896\n",
            "Epoch 2/35\n",
            "468/468 [==============================] - 13s 27ms/step - loss: 0.5782 - accuracy: 0.6859 - val_loss: 0.5566 - val_accuracy: 0.7061\n",
            "Epoch 3/35\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.5520 - accuracy: 0.7022 - val_loss: 0.5409 - val_accuracy: 0.7142\n",
            "Epoch 4/35\n",
            "468/468 [==============================] - 10s 22ms/step - loss: 0.5330 - accuracy: 0.7166 - val_loss: 0.5356 - val_accuracy: 0.7126\n",
            "Epoch 5/35\n",
            "468/468 [==============================] - 11s 22ms/step - loss: 0.5208 - accuracy: 0.7270 - val_loss: 0.5289 - val_accuracy: 0.7249\n",
            "Epoch 6/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.5040 - accuracy: 0.7380 - val_loss: 0.5273 - val_accuracy: 0.7374\n",
            "Epoch 7/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.4938 - accuracy: 0.7479 - val_loss: 0.5231 - val_accuracy: 0.7299\n",
            "Epoch 8/35\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.4784 - accuracy: 0.7535 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 9/35\n",
            "468/468 [==============================] - 10s 21ms/step - loss: 0.4658 - accuracy: 0.7658 - val_loss: 0.5355 - val_accuracy: 0.7214\n",
            "Epoch 10/35\n",
            "468/468 [==============================] - 11s 25ms/step - loss: 0.4580 - accuracy: 0.7703 - val_loss: 0.5035 - val_accuracy: 0.7457\n",
            "Epoch 11/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.4483 - accuracy: 0.7746 - val_loss: 0.5309 - val_accuracy: 0.7471\n",
            "Epoch 12/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.4413 - accuracy: 0.7788 - val_loss: 0.5086 - val_accuracy: 0.7537\n",
            "Epoch 13/35\n",
            "468/468 [==============================] - 10s 21ms/step - loss: 0.4289 - accuracy: 0.7874 - val_loss: 0.4964 - val_accuracy: 0.7567\n",
            "Epoch 14/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.4169 - accuracy: 0.7953 - val_loss: 0.5232 - val_accuracy: 0.7543\n",
            "Epoch 15/35\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.4077 - accuracy: 0.7989 - val_loss: 0.5162 - val_accuracy: 0.7607\n",
            "Epoch 16/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.3947 - accuracy: 0.8074 - val_loss: 0.5213 - val_accuracy: 0.7484\n",
            "Epoch 17/35\n",
            "468/468 [==============================] - 10s 22ms/step - loss: 0.3860 - accuracy: 0.8110 - val_loss: 0.5281 - val_accuracy: 0.7537\n",
            "Epoch 18/35\n",
            "468/468 [==============================] - 10s 22ms/step - loss: 0.3738 - accuracy: 0.8181 - val_loss: 0.5487 - val_accuracy: 0.7444\n",
            "Epoch 19/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.3598 - accuracy: 0.8266 - val_loss: 0.5578 - val_accuracy: 0.7447\n",
            "Epoch 20/35\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.3408 - accuracy: 0.8380 - val_loss: 0.6245 - val_accuracy: 0.7409\n",
            "Epoch 21/35\n",
            "468/468 [==============================] - 10s 22ms/step - loss: 0.3353 - accuracy: 0.8430 - val_loss: 0.5568 - val_accuracy: 0.7495\n",
            "Epoch 22/35\n",
            "468/468 [==============================] - 10s 21ms/step - loss: 0.3181 - accuracy: 0.8497 - val_loss: 0.7219 - val_accuracy: 0.7313\n",
            "Epoch 23/35\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.3016 - accuracy: 0.8591 - val_loss: 0.6461 - val_accuracy: 0.7476\n",
            "Epoch 24/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.2889 - accuracy: 0.8650 - val_loss: 0.6473 - val_accuracy: 0.7484\n",
            "Epoch 25/35\n",
            "468/468 [==============================] - 11s 22ms/step - loss: 0.2693 - accuracy: 0.8776 - val_loss: 0.7448 - val_accuracy: 0.7452\n",
            "Epoch 26/35\n",
            "468/468 [==============================] - 10s 22ms/step - loss: 0.2577 - accuracy: 0.8793 - val_loss: 0.7191 - val_accuracy: 0.7444\n",
            "Epoch 27/35\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.2411 - accuracy: 0.8893 - val_loss: 0.8394 - val_accuracy: 0.7447\n",
            "Epoch 28/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.2251 - accuracy: 0.8969 - val_loss: 0.7728 - val_accuracy: 0.7385\n",
            "Epoch 29/35\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.2167 - accuracy: 0.9014 - val_loss: 0.8958 - val_accuracy: 0.7372\n",
            "Epoch 30/35\n",
            "468/468 [==============================] - 10s 21ms/step - loss: 0.2013 - accuracy: 0.9107 - val_loss: 0.8984 - val_accuracy: 0.7406\n",
            "Epoch 31/35\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.1855 - accuracy: 0.9191 - val_loss: 0.9502 - val_accuracy: 0.7361\n",
            "Epoch 32/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.1661 - accuracy: 0.9259 - val_loss: 1.0979 - val_accuracy: 0.7350\n",
            "Epoch 33/35\n",
            "468/468 [==============================] - 11s 24ms/step - loss: 0.1585 - accuracy: 0.9300 - val_loss: 1.0978 - val_accuracy: 0.7243\n",
            "Epoch 34/35\n",
            "468/468 [==============================] - 10s 21ms/step - loss: 0.1451 - accuracy: 0.9349 - val_loss: 1.1116 - val_accuracy: 0.7390\n",
            "Epoch 35/35\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.1337 - accuracy: 0.9431 - val_loss: 1.2511 - val_accuracy: 0.7307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred_prob = model.predict(X_test_pad)\n",
        "y_pred = np.round(y_pred_prob).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1-score:', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdTEsFBqJbF9",
        "outputId": "a0a4dca9-2159-4414-e171-883508300eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "251/251 [==============================] - 3s 8ms/step\n",
            "Accuracy: 0.7318108074379134\n",
            "F1-score: 0.69470095183975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot the learning curves\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy, label='Training Accuracy')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vDU7hgUGJjoA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "48f60f2f-bd49-4ee9-8774-d168ae60262b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e007e768c0ea>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZYRW7fCFLiQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}